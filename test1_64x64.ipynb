{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 131 files belonging to 1 classes.\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAOcAAADnCAYAAADl9EEgAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAAvV0lEQVR4nO19abQlVZXmibhx73s5j0AOkAiJBSSDMmoXKkmi0EopBY04oICCTLatbfXqWlV2L6BwWQ5Y2i616V4WoqVVrZbV1a2WYltqIgIqAkIVCgrKkEwJmS/J8d0bN6J/oOd83xdxTj78k5Fr7e/Xvu+cOHFiOC/2Pvvbe2d1XTuDwdA95Ht6AgaDoR22OA2GjsIWp8HQUdjiNBg6ClucBkNHUaQaNz878lu5VVXNeNA8D2u+qkovZ1kvekw15t+9IvNyXYdzVxXvLlew25w5RlmGcxdFuFS9ltrhb/l/VYVRJyYmqGk8lklH/o474nhdOscsC21FwfMYDkde7vcH1LZz567QNhF/pHAbG2O4uoQf4dw4J+f4WvC5pI7Dd+C54/AXj5Fleavc6/G7g/dYnyf2bTxrfF9gjqnr1HNjG84D33uFjoFYsnBCX93nxoseYTAY9ihscRoMHUVSrY2pbc7xJxxVM/2dZUEFKIr4p72pOoRz4zxQ1XHOuYraWDvIYI5JqgWoyqqZ1AlVhVW3uNqf5Xh2mSOMkedBHo1G1O/rX/+al5cv34/apqeDWjsqw3E/vf2n1O+yy67w8o9+9GNqW7t2rZd7vaJVds65qkqpce1qYr/flzHCvcrzuKmA74CSZXCMlMqo58b7ivPX8Vl9j789g0EwD/SZ4Rz1/UipwL7PbnsYDIY9AlucBkNHYYvTYOgospQ+/czUtG9s2GK0ncxj5GADkDtDbAPsV8sYFWyx52TbqZsi7mbJwV6q4bhML2YcxmjcDeir+92xLXu1wdGWTLkENm/e5OX1679H/ZYtW+HlNUceSW2zZs3y8gDcVXfcwTbno48+4uUVK1dQ29333uPlV7zsZC+vWnUg9RtMgo1Y6d1qd6U03RRoS7Z6EZ4bLfHpwNe2Ye/DkHkWH4RsQnnyOQyiey/olkN5pM8d31tdZ/B73yVzzJViMOxNsMVpMHQUSbX26ad3+Ma65k92QltwI1AXih50FPUmTzCGxqip0LZ2XK1VvbOAbXQkqYyFsdIHNs5oyNvhk7PnebkcDamNXQJ5q6wT27lzG7VcddWVXr766mtgDL43PbiPumWP7oLR9DSMEXfbTEywi2EMc/yz//ynXj7uuOOo32vPPDOMJ+P3i6Dy4j0YDndG55HnwlQCVDW4PeSFw9egoTZn8P4VcTOCmGyi1paj8I70C3Yn4ZrBdyDr8RxRNdZVlsEY+yxZYGqtwbA3wRanwdBR2OI0GDqKpM25adNO36jbyWxjsco8Hgd9Pe+hKyLO/G/ODDvCn8W+QLqa2qNIPctcsD2mS+0X5NkTkzJHjLBRexdlvBalgoXjPvbxj1LbO95xqZfnzZ0Hx8gYMKa6ahBoB+a9uJuiEtdVD44r4f7cdddd1G/NmjVe1iidPAMbH+3xHrs60OXVE5uTrjvDqCKxkeEWqCsFu5byrJFuh/dRXVxoczon1FKHNj9EEvWUpojXwvPA93jJ4vlmcxoMexNscRoMHcVuXCnbwJXCbagyquuA1NrfM6oDt9FRTawrVY0hILeIRy7QcaLCYKSLqmqkoo55jqNRcFuwGs7X/Njjj3pZg6jngKtm1uzA9NHrxHuVihYqJtB9xK4fdDtlyswhj1f4gc/SOee2bNni5YULF/K5i6AyYrRQLWo+XgsGijvn3KxZwazAd7MQdwaq5WON1HfoSmFVE9/H1H1EM2gszz3L26OkUK3X8VPv5lJzpRgMexdscRoMHUUy2JqDZ7mldkFlGo9ljQNDowL1SXfE8NOuqklM3dZ59HLcxRxpby8VvaCuagA1kfg15wzOccxqYg7nRraTaILuuuuu8/L7/vy/8AzzMP7NP7jZy/0B36ujj36Rl+fMnk9tI2QuwQ7hV//+76nfyScHQvtoxJNElXrRokVe1ueAar8GYhOh3bWzp5xjVRDV2Ofa2neY1ezBXem+zAN3YfWd0GB9P0Zfg8pBNe6riRHUV1Rdx5WeCwNAtC2+k/472JfTYOgobHEaDB2FLU6DoaPYjc0Z0EieBb8bcaQVullCo0ZTUKBtHY9QQbtn+44d2uqlwYDdIMgGIftZ5ovB1+NSc6xiULkkaSrQJsd+bJuuXfsKL2uUxCOPBjfLH570Ui8PJTpmw4YNXl51ALNq/upj13r53e95r5dnz5lD/f7hf/+Dl88662xqW7Ag2LEVXOcTTzxJ/Q7YPwRfF2LrjUbgYgCbczhkdwm6N9Qeje01NN118URj+FtzJaM7Cd+/ciQRUzkG0vN+SFW3J7BLf+ueBztuBqMZDIY9CFucBkNHkVRrU/lAifWRCbtnHFSyHqhxykrB7eq+EpvBH4Hp/OfNmy1jxPOjxqDE8SLD2yDlEkB9KkRFqoBUncN1/vCWH1K/ZcuWhX4SRL1y5Uovf/WrQe1cvnw59TvxxBO8fO/P76G2d7/7XV7+H9d90stXvOtd1G9cglurL+oePMO6DPIPb72N+p133iFeLiWHUIalJqBpUMyifj0wiVIkfkTTJIqXS8C+akawOolB33wtaJpoUDkx1ij4QXNHASNLhoi5dOj43fYwGAx7BLY4DYaOwhanwdBR7KZWStDdUyqyBltXRKnDHKVycog00EBptGPRbtU8p2hnpupdpP6eCrrlehoaMBv69iDQ9tZbb6F+F118YRjDaaB3GOPss9m9gcDt/O997/vUhhS4iy66JJxrzPeqyMGFoe4vkG9af5OXzzzzj6nfcBhssZ7WIRmCKwVcFr1BPOFZitKJz6VJAQxj4Jyci9uV2oZD1lKKcDgK7p9UZAvR/Ard82hPBNacYzvsy2kwdBS2OA2GjiLNEMpwK1gZGlgGQQ6Dvhg03MghhMdJjpW6aq9wrEgxRWLB3Bq4S5EF43iul1EjLT9EokAA7tZtW6lfvwhqp6blL6mEYfi7XvH73heiWd5/zft5DBjyX+6+y8tHHfUi6lcMwnWXI76WJzY+4eV1p6718kgDjenZyiRBjcshqFwdcqiupkrjMdMnzlBrRKwkAtPZlGqvUO0cV/7W9zZW1hLVep2/uhv1HWyDfTkNho7CFqfB0FEkv62cb2XmqkMfGSGg06TUD/0/gewKVlfjLCPdAYsFtKb6pYjYlZRxwHPv2hVX1VCtLUeSkrIfyPrIispE7bnsind6+W+/9CVqW7bvPl4+9thjvKwlFzaC6jp//gJqO/DAQGgvgajeZInFq7VhyQi8V7WWUkjsVHJl69BP2V/4nFIqor6bqQrk1A9zFDWq6AGzDQKxi76YVbC8ypLPOy6NIWQw7LWwxWkwdBS2OA2GjiJpc6LO3Guw9oMuj6Xfng9SUS/TUMoOTceellkD22OHBGLHKhBrLtaZbGs751y/J6UDwH6ZhMDuvFEyAtkmPEYFybl6GLEirKsXvOAgLx900ME8MWAPoavm5/f9grqtWnFAmMeAbbgh5I8lW13tc5hXLe8Esmxq2BsQD4PrQ4Ks0nG0SQnPpof5cyX3LTKmGnse8CwysRfrCqKkKP+sBFtDKQt15ZE9XSF7jbq5jFyRcSZUDPblNBg6ClucBkNHkdTnkGSurhRKva+lFBrp8Z9Do5IT5ReVatORwGntl9puR3WVKhCLChPbvte2nbu4KvX113/Wy1dcHlwdK1fuT/1+APloz3jNa6ktA1UWWTt6D1P/Rb/x9W94+c6f3enl/fbbj/p94idhHueccx61LVsWgr6x5MIJJ5xA/bZuDeyn+3/5S2p74MHwe+nS4N55xcvXUr9sEtxHUjKiQrV2Yhb8Pe7+quXujCEIvG647/LWtkZ1bCLI8/j47scrzcUrn7edrw325TQYOgpbnAZDR2GL02DoKJIlADdvnoYSgPF+qj/Hog5KtaPABlV7kXR+1OvFxdCDLXu1R2Pl3jJNXAv/o3pSDXrbtmBnfvFv/4baTn/1q738pb/7Oy8ff/zx1G9iVkhKdv/991HbG15/TpgXunskb+3111/v5aOPPpra5s2b6+V7fx7cJ+eccw71O/8t53r5Lz/4EWp76unNYf7HHhvm5BjophjJ88zA1kNLT10d+Gx3bOcIngcfeMDLDz0ccvpqbZdFS0I9lwNXHUht+0PStMlJrsXCFbeBtqmRT1X8u4XvFe6jNN09ELmViHZatq+VADQY9irY4jQYOoqkWvvMMzujam2qQjCXagB2v0TnFon8PxRMCypNT5gtWG1ac5uiKwXVj1K372laPMcvf/nLXj7nnH9Hbf/4tf/j5YNfEFQrzEXrnHMLF+8L8xANBlRDVNk1xw+WGGwGn8NxUEFZ78cVl4X8Qtdd99fUNsbrhhvymc98hvpddvll4RgNlIZ5jBJB8OTiKsV1hXmD8F41SlC2B2U751yNDB4+jFhk999/v5fvuedfqN/+K0Ku4UMPPYzaVq1aFeYLrp9pMauI8SXvN7pjTK01GPYy2OI0GDqKpFr72GObfaPupvYHQGyeViJ5YIBMl5ganwlJqGqORCXA73wNqmsmxPea0icquTioVnguTa9fO1SleIx77g7qzk9+/CNqe/0b3uTlb37j617+6U9vp35X/UXI+aP3IONESkFqVPBG4r4ysCDXDgQCTw+nqdef/+mfePkjH/04tU2DeomVorUExebNz3hZd6/fccmlXq4qHI/J/gi9FkyzSvl+RJXH96UR9I03T3bm8X1H00n1SiwdMnbKMoLjIqk8nWN1e9OmzdR26623evmii84ztdZg2Jtgi9Ng6ChscRoMHUUyKiUVhIzB0HnG/XZBAHEqeRZuxTfKuEGK/QJsSbUJSf9vMP3BpgW3QiVlFb7z7Ru9vHHjRmo74zVnePnXv/41tW17dsrLr/vjs7x8773/GpmFc7mUY4C0vhxILm6KcYUl6fR/KoyJpfGk3+GHr/HyaJrdLJ/61Ke8vHB+YN+85bw3U7+FC0JisEsuvoTaMGLlK1/9ahjjLW+lfgOwQfWd4LJ8YGeLG47qSWugNOa7lfHLyB6FvjljcMfkmb5z4MbBXMO5stzCnPfdbx9qe+3rznC7g305DYaOwhanwdBRJNXaAZCcGxWIYatZXRMDZLNAunpVYUpksCh7CEoH1BTozVvjyETBSl/PnTz0vf6GQBw/Ze0rqNu6deu8/MEPfpDasMLZmWeeSW233/4TL995ZwhyPvDAVdSvgorHWRVXy1F9l9hiUnlTAeFYhE2D4AeTIXh5YoKrTb/3P77Hy6ju6bmeffZZL3/oQ3yvrrzySi+//cILQkPNr9kNnwuso/MvvIjasFJXOQ6mE7qSnHNuEp6LpuNhYpFUWoMyC8lSHkX83ceq7mO4PxONiml4DJsRTXW+CftyGgwdhS1Og6GjsMVpMHQUSfrepk27fGNZss7sMrCjZKu56EECJ9DPm7p7gG6HV0CZKsCm1TEK0N3/9Rfswrjjjju8fMH553v5lpu58vTttwe63b9/57t4HkBD0wre+HsMVMEvSS2Tc88NQc5qB7ILCc8Vr7CdDG7HuyrP9uv/9x+9fPZZ51LbuG5PcpaqPF0JNW7H1hCY/oEPfMDL//XKq6hf0Yf9hIrHwKDyCy54m5cn+0wBRDef1iHByKI8j2+r4LU1ktTBLVaKYcxW7cl+CD5DtJ+dYxt66dJ5Rt8zGPYm2OI0GDqKGQdba+AuqlYTE1yOAT/1JbhIamHmIOsjc8rkgIBomOLXIMDZOed2QI6fN5/HTJSpqZB/9Qt/8zkvX375pdRvYjAnzGkcV5GaAeFB7kEl55tuWk/9Xvayl8OveFA5q6vxPKqqgpEaCipjOeSg8h//+DYvn/SH7E6q0JUF/pi6VvUaojDGYupEoGrhlVdd5eVr3v9+6Ys5Z8Nx3/rmN6jfvznpJC8vXrSI2tBEUrWcyjEg00c+U6gq531V7YMZMRpDOQ1xk6Frr1nBO8j77GNqrcGwV8EWp8HQUdjiNBg6iqTN+cQTz0YTfKGdqVv7+Jsj1sXeQrtK6HvX33CDl/8IIkMWL15M/Xq9MOa1f/VharsU6pfMnwfHJepuqE2INlCqvAVmU9DIliVLliQObI/CyHK+HzjHZvYAzIQQ5F/exzly77oruJZe97qzZfx2WSOOqojLpW1ev0PD7oMTTE+zXXw1UACvufpqL/f7UmYSxrjz7p9R04IF87y8an9OttbrYdI3/DZpBjGwRyU6K2b/V41MCO0J5p4bI9wrszkNhr0MtjgNho4iqdZufHqbb2yUzaMETvzZH0IUBiVbku3kEeT8/PwNn6W2Sy4JgbzITrrxxhupHyYeO+2006mtrtBNAREfjbJwQR6XrJqha6Ju5OcN/9se3RACsZcvX0H9Ujl+UZvHXKZ5j58LBu7WUiqgVwCDCsbftWsn9fsJRNGccvJaakNXGb4SA1En0X2SKmOHzCrths9FE3AhMCfsd7/7XWr7zW8e9PJbL7yQ2lB1HQiz6JdQDmPH9uCGO+bFx1C/jCJzeF4jcLfhM8sqZRLhPdAymeH3smWLTK01GPYm2OI0GDqKZLB1Diqdftv7oEo1SgeMYbcWqmV94fOfp37rTj3Fyxe87W3U9sUvftHLc+eGKlpnvJYrQ/fg/4ts+AppHRkwPGFUg9wg/v+quSsdxnnwwaBmrVjOwdbIBmmoeJRHFSuh6e4ejSiDQF8Q80KZLWGQ4VArhOP9iZPKM8ory+OPS8wDi6pfvJJ4NZY8xJFK5VjRzTkO1Ff2zfr1N3l58zPPUNstt4Sgh49+9Fovf+vbzEB6bMNTXn7rW8+ntiF6IDBHVq3XEuZ1xTuZlfaJT3zS7Q725TQYOgpbnAZDR2GL02DoKJI2Z43ZojRvKEWbcNunPv0xL++/IpTGO+roI6jfY489BvIGanvLeUHPL8G90dh5x1KBmukJWB9oszXy5zYKxQWgDVSLvYg2Jya+qpUJlaErRc/VzjYZSxByDmyW0ZhdJGOwdWoX7LQ8YzfCr6Fq9Clr11Eb2q1kW0tyLmQuVeI6wORcNRw3rnbxqSL1SpwTe3SEeY2ljCAyfQZs+57+qle2juecc6effhr8Cuf+t6f/EfVDds/OHXy/p3eG6/mf1/13L7/xjW+ifujumTdvHrXp9bTBvpwGQ0dhi9Ng6CiSai2mpK/HvPU+mAgqzLUfYsL5f3jPe7387W99y8uPP/4Y9Xvxscd5edm++1IbMlbI1SEqKG71q4qE6iupp5ILiGjv4mZBVTPLVF0NR27c+JSLYTjE8hTchnNMMYlKKNHXKyZ5jqgm4tVI2bwNG9h0oDHGyKYKf9dK3EjY1grbpJYDi6Z2cXNDmVCooFZx7xc/TzEBxpHSj845t3hxCELA+RJryTlXQvmLvqjNP7gxBNNfDpW+r/mLa6jfccef4OVNm7kE4HZhb7XBvpwGQ0dhi9Ng6ChscRoMHUXS5kT7pRI/wn/7+Me9fMEFb+dBoex8OQq26mmnnUb90CbS6Ae0Z5B2prYY2hSxYF9FnYg80ZJxQsjiOYL9tWhRsGW0dOKYbEK2X5xDKhjkQJVueYb2M7ehJyuj3Lf8zObPm+/loSRsm+wHOxbtxbHsNeRgg+r4+JwcUhFd3DZV71cejQZJROk4pVXGE6Vl8MrnOSbq0gR2YP+XfO6TILnY974X7M8jjjyK+iHV9OBDDqG2hx5+yMurD+SAcD+/1r8aDIY9DlucBkNHka5sDbpVLtvml112eehXcOk93H7HXEO6rT0xMcfFEAvWTTFKlPmD6hOWM5Rdc9cD1UcDsWnO4kopIbKDWC+SnzcnhpCcu2hXy3sSwI5qVimDFJFycmNh8KxevRrGl4iS6LlFnXRSChLbooH7GgXUXnHcufgz0+de0/sR/8ZoVWqunB3aJiZ4jOF0/DoxJxSWj8T5Ose5ko444kiehTGEDIa9F7Y4DYaOIqnWMimbP/NYGVkJ0HjcmjVrvDwt5QEGs4JaiyRn59LlBxC4M5rayeXqWDwGqeyiPiG7ZzDg24Vq9KpVGGAtTCXUjBMpL1GdzDPevcb59xMqEY0n17Jg4YJoW0a7wfH8P6gKNsjbQHbHUgp6zfh+YEC1c7o7HK+65hrqKrZV7bLjXd6sRpNC1GYH71Ij/w+abWAuyU48Bo6o6WeVrQ2GvRi2OA2GjsIWp8HQUaRtTlC7C63qTNWDNe1mGPYFq1/oZa1KTW4Q2Q6P5URtBErDGLqVzblYwX7py2XHY63lfDynHrQ98sgjXj7m+OOoX0aJxmT+wD4ZDAJLJxUdo24QvM5UBWy0zxssJng0bHPKcwG7SpkzHFQOtnqPnwvtUci9xyBqdNs0yi/SfgiPUWFeX7GLOXgeEwbIveqFZ1HW7O7p99ujh/RLR3slDVYXTlpKTUTGMxgMHYEtToOho0gzhIi9IjltMiQoy3Y1BijD33uqFpIbJB6QSyltHLtLsgKCkCUweOxwjnHXTIZMKAnc7cFWf64MGKjAhSUYGnl886DWqXqG7hl0IyhDCFXZVAkNzFWrz2XT0yGH605xa01AFeaYW+W531hlTJ9Zu0rdeD+QH5+oUFeOgqwmC6qTqqIj1JRClwazy5TEHzfbmE0F1yyuFKrWlsfV6xjsy2kwdBS2OA2GjsIWp8HQUaQTfJFuzfSjVMAs1Y8AXVtdACm9nv9vtOef/e0oXhqKHVURNS6cu9Rga7LntMwf1v9g4P2Z3hXOXY40n2s7jVCBtpP2S9G9yObC+yP23NJ99vHyRK5Us3aqZqO2C/7QPL7QWkSibfRAtb1iriC1HZH2p5Et+DzVHsW+2JaaR7KSOFYcL/XdwWemzz3+Hvjz7LaHwWDYI7DFaTB0FOkcQpTHJ/4ZTuWLTQVDsyqh+VHbz6el8TKqkix9Keds+PuERAhgTiFVbwoYtJQ8MwUwRaa2bAp/F1UKT5fnfG5Xt99jdaVQjtWECobnLiue75FHhRw327ZtpbY5c0PECo4xGompUKOpw8+irFGthbxMWkMDCUJyLWWkvJ72w/eqEYgNfVXlRcYQRSclqnQre4hcezAtvR84r6qW4O346Tzsy2kwdBS2OA2GjmI3Vcba1RTnZk7ETqkYrPqkGBrx/yGp1JjYRruuCVZKiliv14m7wycc/xI8M/XD6s2aJhKBO5DNlJHx3UOc/2g07eVC0o3OnxdU13vu/hm1HXX0sa1z0iDh4ZDoPTzHAuaIapyohY2NeWyLlKdI5Yd6Pu8OpSlNqM24m6pqLVZ1w/Er2VHm3dq4yhuDfTkNho7CFqfB0FHY4jQYOordJPgKUFcK6ujK3ojZA8mtZo0UmWGwNZ5b22IJvpqRCnFmTsou+cUv7vXyYYcdHvppBjGab9wuHg7L1r87l7Y5aV6Y31ZsfKzg/dBDv6a2I486pnU8vVeU/7fh3oDj4Nx93a+Aw9RlhkwxTioXT+jVCBaC2z8WJk6PIm6A5aalNhy+t/FvGAaON5KmwTNrrBGLSjEY9l7Y4jQYOordMITiLgZUfVLE4NTfG+wNQEwlTW1Bp0oMpPohVP3AOWPuGOece/CBUCnq8MNCuv1MfAWUvyjhqqH8NspUAtUw9SwqUNX6yoSCtlmTXB07xsxREFNJrnNA+X+hQfK+Yu6lulYCPvTrzewdS7GpcsmZO0aWF7hIxqJe79oRKk9Pyr2KlYzQbx0Hz1NTw+Rog305DYaOwhanwdBR2OI0GDqKGQdbK1IJs2I2Z4p2lrJzUm6EVKKnnGybuHsgFRCO4w+HfJ1TU1Ot/XTrvY5QxvTcZM85xnActwm5jkq8dgy6C7RuTSzgXOvDYGnGWqJ0arBxCzpO3VNBzuX7gNe2c9d2L2NNEuecq6j6Nl8LlmocSSm/4TDQG3fsDHblXKA2Oufc1FMhGdo9d99FbRufftrL23aEOfbExn/xi17kZYwIck5t3EWuDfblNBg6ClucBkNHkVRrUxEfqVyhscrFKReGIqYKppgzqVygOEYqwiYVsaJBw1mOLhI8Lh4MnWIgYVSKVtimKtUyR8qPNN4Vzqsl6WD+6n5ASyTPMZqFr+X/feefvPyzu+6iNhxkzpxQ3nHVAftTtxf+waFeXrZsGbXhPUDzQB/t9DCopJ/+9CepDd/VWbNmUdvBB6+GX2H8bVt3UL9tW0Mw+g5QXZ1zbvac4FoZj8JxO0b8rbvn3ru9/NAjD/IYs8MYqw+60LXBvpwGQ0dhi9Ng6Ch2wxCKM1twx1PLIMQYMek0iFpVq51wPh5rGkTJyRMBzlfV2pmWOlCV9wBQ1wqsXFYrUyQemI5qLpoAWvEZz9zYRcd5wX0bCLNlOB1UwWeeecYx2nfONWfTSSed5OV169ZR25zZQZXduTPsiuru+A2f+2svv/3tF1MblvlAtVYDBiYnwrn+05/8GbVRaQ95r5Ccn9Fzp25EaE/tsHN6TR2japV1jBjsy2kwdBS2OA2GjsIWp8HQUSRtTtyuHkiyKC5bIMNkYI9Ck9oNGZYEqOMMIYQmnErFrMbcJ88noJrtLx7/mGNCgDKxe6SMYKzsnI6PmKnLRcccDMJz0jEGg3DcwkXMiKldrDo225ypEga4T5DnGEXD1zw1tdnLul+BbKKK3GlaihDtUW7r95ElJSUdIUqlwmfRCPpuTw7nnHM5vi9g39apxHFqj44kj20L7MtpMHQUtjgNho4iqdb2C6jI7FR1wErIWvm3naSN4znHrBfcunaOc7hg3tBm0G0qt0ycnE/nShDw8Tp/89CvqG2//faFk2Eu07iKPlPiu7ofUoHvVOkK1bNMXDpwj5csXUptqHpz0DfPowflJB559CFqO2j1C8O54H2p5RkdeWQggTcCGep29b2qxYVGamc8gB3Va+f42tANN4R8v85pjbuGjyScC253igFX9Gfm8ovNwWAwdAi2OA2GjsIWp8HQUeyGvodJtmQrO0cbSJM0YZ0JHE9ofhXWEIkHEHPNFqW/xceP1dpQOwdtG7X1KEh7pHY32NB13B2TonGxDdRrlRWpIPicXB3cb9u2EF1x6AsPo7bMtducCkxodfPNN1PbgQeFiA+0A/W5HHZYOPdoyOfKYV8Cb1XR4/0K/K7o+EWBewhaY8W1oielGZE6qHsIwyG6neLUT8rxq1FG9Azb7VH7choMHYUtToOho9hNOQZ0YcQZDc0A5fYxmlEpQe6J2oJqAOd21XPH5xEr35cVOl9QLQeiYkDXqa3P8hyhsQ9Ml1KiUlwiwkHV9N8hxXxKlZ0YliGfjua0QTVr01NPUds+6Baq4q4l1M4woNo557IKVXQoqyBjLAU3ztSWp6lt331WeBmDxVMuMyVZcb6oeL5bZpAp8wzKfEhg+uQkJiFAFhPPoyzbWVfOMYspBvtyGgwdhS1Og6GjmHE5Bg1QJlZKY/cz9C1LYF401N/nH+ScUl1TKfuprZG6ElRvx2OMiKAcr+41JgK0/M+D3WttwnllGaSWlPsdK9vgXDwH0lhYVz14LjuHzIjBnWjU4vR+oJp/6qmn8jyQxVPhc+Gdyrlz5nv5wQc5t87Spci6gnNX8e9II3C5ju96x7wAzfIXeBzPvyIWFrojZGIZMODk9S5HOOZ81wb7choMHYUtToOho7DFaTB0FEmbM1W6DpNRNfPA4vZyAbIGW4P7YRQvkZAq1ZCqjs2l4GD+YothBIWaL9u2BPfJ97/7z9R23DEv9vJoBLajBI5TkrOG3dpeBkEDiHm8uN1NbWJHbd68xcsLFyymNrSxxgnXD5ZBmDt3LrXddNP3vbx2bbBH9fHh/Xj88cepbc3hULYAIpTV9TA9HVxGDXsxUj5Sz41oBrfDGLKXgQwhzItbJap0N5+ZBVsbDHstbHEaDB3FbmgK+JnWIGRUx+L5bjCIOk+oSE1C+8y2vBFFkaruhYHX6oqIM5BQddu+fRu1UT7aHPPWaCU0mIckk4lWIJNq0OUIVdd4XlwKLpYxvvFPX/Py+W+9kMdHNQvU8qzBzAnznZjgvLgPPBDcIutOeVWYkz4XuP9PPPEEteG1jSAAuqme/n6BAbGg+2aZD3xXef5FEfI04al0aJxjVe1ejVXYl9Ng6ChscRoMHYUtToOho0janMjUL6V6MOrQje1p4Kj1irirA/83KMUrlkc1lzyqoyFEnhSScxbso2ocz/uK2/Jqj2Ikx5NPciQH3gM0uxu5byFXaib/D9F2x9tTJ1wAahejKwvHe/iRR6jfuee+PsxD3BsZ7C9wkH080ZiWB8T7yHRDjcQJ833yyY3U1h9A9FAZ7r0GTbs6jFEIHTPvtQf7O+fcuESaIt5TTiCGN6hBl4S+uG8y6HO5wSFUD1cTOWUz+z677WEwGPYIbHEaDB1FmiHkMP+sugBQ5jaM5EiQeyhPi1P2EATakiolagoyR+oq7kopSIVhlRGjMDToFs/96le/hto+/OGPePmyS6/wspY6yPN4zlI0F1Ddm57mqJFUnuCqCmoWsnt++MNbqN9ZZ50V+okZkUNwdEblAHm+bMLww1iyZElkjsqYCr8XL1pCbRUFDyWuuR63ys4514PonunpXdRGuXArLGOpSwHcd07Ya5QfCauRq2ocd0VqnuY22JfTYOgobHEaDB3F7hOZ/Ba6WzYxEWfEUP4VYKz0ZIcqRXxHlRd31ZopBnFnLl6qAXPJKAk5xkZyjpURrOrsnHMvOfGlXt6yJZDKr//sZ6jfKaes9fLq1aupDVk2OI9f/eoB6rd+/U1efuMb3khtc+chAT3Mf+XKZdTv0Ucf9vL+Kw+ktiEwkKiiXKa76GjP8H08/fTTvbxzZ1AnNddQCfd40eKF1IY3HHMP1ZKyFNXCiUkp8wHvo+7M8/ONJwxAVpfu4FPVuBL7xSvIaS4jDRZpg305DYaOwhanwdBR2OI0GDqKLBXlMbVlh29UHRmDrZtJlCBY12H0CtsoeFwjOVcPk2cFe0NtCCyf0Cxh0O6CGTcCa9vl536HP3znO9+htnXrQkAxR87EA3eV4cQRJXgQP5eyhPKAI75XExPBRkT7/Ctf+V/U7+yzzw79crbTMLgbg+I1ioYTu0nkDDyL9evXexltUeeYCfWzu+6gtkP/4FAv9yeDPV6PdR6Jcgz0ikgJEErKFo/0SbkA45EtcTsS14tzzDybO2fQejb7choMHYUtToOho5ixKyWVi0VVzfG4XeVQFZpcH8IQQjUOjxs1XC6oNvOcVb0Mx6iq09rtt/MI57vttlup7ZWnBnWtxhylclo8nzKtUH3lSty6fY/3VO4jMFiqcbgfW7Zspn6ozmNggXOsDqMqqPOgqTdKS4TX6eGHg9tGXQwljNnIPwXPDFlLmoO3dnFyO/DNG6ZOLHA/Vflc32+8J6kxUiYjq7laQe052JfTYOgobHEaDB2FLU6DoaOYcd7aFJo5P9vtTN1ORmhFabRFZkJ1apsH/sYxmjVVZpbnVG0spBgORxiMHqcHptw9vJ0fr8uScvcgy3JUxu93g2oGciy3a+NcjdJ74Q8YVZN6jdSmxXNH8w7L7yZ9dGZ2IMpqV/JeRjwpWyr53Ezr/8RgX06DoaOwxWkwdBQzLgHYrEodjxSJfeqbKl37uVLjN7e128vf6fm4H/9PoggHYNs459zU1JSXX/nK06gNt/NRPdPSAbFSgdrG95u6iXodz/GL17z12a3UL4uq0JKnKaHKxyqOO+dcDqbDvAUh4LzBmIJ5zJ/HESuYK5nKKiTuW4o1puAAfCwVwteJY+h4k5PtkUQpNTZl+sVgX06DoaOwxWkwdBS2OA2GjmLG9D3Vp1PR5qijp3Tr1JZ9bDs8VVpeES/VHo9wwPJuzjl35523e/m4415CbZSXNGGDp+Ybs1O0H46pLqlYdM/27duj59LHgs8s7fqBOUrbGErZv+CA/cPYYi9mcG1L992P2h57PNROOWj1IdFzp+4xnUsuNPY+6nuV2svAtpS7B++37mWk7GI/3m57GAyGPQJbnAZDRzFjtVbBQbdxVTOl4qaqY8fOlVIxUmpFSv1lFYnVzO9//wdePv74l7rfBynGSirgHBFzdTjH9wSDuZsqczzqJTV+7FzKQCp6IbrigFWcQIyQcI1NTW0K3WB8TZDF+WdnHg2C71mS3ZMwx0aokiaeLT6LUu6VluVog305DYaOwhanwdBRzJghpEjtZiFmSlDWHcgYe0N3uVLjc4Vt3IFUdkw8L87KlWHXEfO+PB+k1HKcc4qRlcyti9dZx/vhT1XBYupeOhBAKmyD2rx85Qovb9kyRf0WzA/sId0NxiDtY489Hlri71hqR1bfiVjwhZpVqTFK9FTg/GsNHIfxJBcTl27g6mS/g305DYaOwhanwdBR2OI0GDqK3zvYOmVHoU6ONkWmLoDUuUGmrX1lKqG7RBkrEXvOiV2J/aamOCnWaa/iSBQE2q5oq6odheOr/YJ9uXp1PHBX7ze7jOL2eexczsUD05MBxFJzhor+wbl27NpJ/ebOmx/OK89i+65QYwVrqiilCWeVckHpOxa7x1XiXZ+pGy7PxaUzQ9dV9Ly77WEwGPYIbHEaDB3F7018T7kw+pivJ6GaoOqTJ9RVPKoSPQVzsY6GrMYNIiySWlhAqMbdeOON1PamN745Nn26bkzF3ywnF36ntuxjhGqFPotYvpvly5fLuaJDRt04qn6RqaBtWGaxCHO67777qN+y5cHNokyZDRs2eLkEt0eeJwL187jK22SNYb/wo5ScSgU8z0oDJcCcQXW4rONuPjW5dM5tsC+nwdBR2OI0GDoKW5wGQ0cxY1dKKkGRug7QlZJHkmw5xzq5joH/NTAKQHX1Ptp6eXx8sqOkVFsONsXmzexKKSYCZa8S10SMttiwc0BWS5ISVaGtjgU/EufS8dGoWrB4EfVD10QuMynydjeLPjOMBlHbPe8DtQ/ssqc2bqR+TP3kMQYTIXlW0Qvnyntx108l11KX2Mb3DSmYyQB8TIaWcCcVMF6DGoh0Sd0nsKgUg2HvhS1Og6GjmLFaq0GxM8m7qWMko1wala2DmtVLsClYBdNq0O15WnQet95yi5cvvvhiaiN3SSKYOxX0jS4HVQXpXFW7OdDoJ9eFv4fAsFm6dCn169E8GHivMDfS7Nmzo/NQ9wP+r8+A+XPEmjXcjf0ZhAlQE9GESUYtieqaykeL5y4T1dmpKLqopLEkAal8Sw3XWKK04u9gX06DoaOwxWkwdBRptRZ2yErNfZO3syScc65HOW3iROwBpAvU8UegWmE+l2RqSVEVYkRvrZL8zW8FVtCJJ3L6y1TenRj5v0HETpyb1FccI0Fa16BvVLMmJsM9bbC6epheUwLT6zDHz3/xC16+9JJLqN80PJdeIWocnS68WvuvXMXzwGct5hI+wxrkFFE/L7gtd/HdZkQvws5yLp1fqBiEOdOz1hIaLj7+YAaV8+zLaTB0FLY4DYaOwhanwdBRzLwEYKJqtG4KjyPJvzQiA3V5tUfRdVNGAoF1HrqVjW1lgmV0yCEHw5zEXoSkTaVs5+P4t912m5dPPvlk6lfAtWRjieQAGzTlupppQrUM2E8LFy2htq3bQtDznNlz+UCw6S55R7AzNV8s2ne5JPgqx+EeF0WY//S0MGfmhIRWeilLlgZWEz4ztW+TeXYTlRpwTDwq5QZpJKbDAHHch5D3KuVem0k5CftyGgwdhS1Og6GjSKu1qK8q8TiRM6cXUbs0xf00qIkauItb9lhJWFkpyA5R1bhAdw+ceyik8nkLgopXilpbjMO1pdTyl4MqOxZFv0Z1T4KGyVwAFanK4mUbdP4EuMUnHH+inAuZOVIFHA/M424hPKonLowrr77Gy1ddeZWXlyxcQP02b97i5X/+Lge345iYo6mQ92MEz6kuVe1Ed0w8vxCq8rmaM6iyK/Osag+yzzSfMMxfzcKyNLXWYNhrYYvTYOgobHEaDB1FlspNu2XbtG/UJEe9LE6RigXrNmxCDC5WWpuLUPY0MVKK3I8VsRPXyWX4NHogkvtWfqM9jfVKnGNXSj2O36sUBTAV3RNLXpZLv14vvsWg99+fSyI+KEBensXDjz7i5V0QHbNiP0409tSTT3r52ms/RG1HHXWUlw87/Agvz5k3h/rNApri7Nlca2TREnAh1XFaHs5+x44dMsenvbxx4zPUtnFT+L312W1e7jf2VMLewIoVK6ht0dIwxzNOf2XrJo19OQ2GjsIWp8HQUSTVWoPBsOdgX06DoaOwxWkwdBS2OA2GjsIWp8HQUdjiNBg6ClucBkNH8f8BOcYMhZb8fgQAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "dataset = keras.preprocessing.image_dataset_from_directory(\n",
    "    \"Resized_color256x512/5\", label_mode=None, image_size=(64, 64), batch_size=32\n",
    ")\n",
    "dataset = dataset.map(lambda x: x / 255.0)\n",
    "\n",
    "for x in dataset:\n",
    "    plt.axis(\"off\")\n",
    "    plt.imshow((x.numpy() * 255).astype(\"int32\")[0])\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"discriminator\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_8 (Conv2D)            (None, 32, 32, 64)        3136      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_12 (LeakyReLU)   (None, 32, 32, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 16, 16, 128)       131200    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_13 (LeakyReLU)   (None, 16, 16, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 8, 8, 128)         262272    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_14 (LeakyReLU)   (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 8192)              0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 8192)              0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1)                 8193      \n",
      "=================================================================\n",
      "Total params: 404,801\n",
      "Trainable params: 404,801\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"generator\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_5 (Dense)              (None, 8192)              1056768   \n",
      "_________________________________________________________________\n",
      "reshape_2 (Reshape)          (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_6 (Conv2DTr (None, 16, 16, 128)       262272    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_15 (LeakyReLU)   (None, 16, 16, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_7 (Conv2DTr (None, 32, 32, 256)       524544    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_16 (LeakyReLU)   (None, 32, 32, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_8 (Conv2DTr (None, 64, 64, 512)       2097664   \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_17 (LeakyReLU)   (None, 64, 64, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 64, 64, 3)         38403     \n",
      "=================================================================\n",
      "Total params: 3,979,651\n",
      "Trainable params: 3,979,651\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/300\n",
      "5/5 [==============================] - 2s 229ms/step - d_loss: 0.6646 - g_loss: 0.5250\n",
      "Epoch 2/300\n",
      "5/5 [==============================] - 1s 118ms/step - d_loss: 0.6598 - g_loss: 0.5682\n",
      "Epoch 3/300\n",
      "5/5 [==============================] - 1s 118ms/step - d_loss: 0.6604 - g_loss: 0.5506\n",
      "Epoch 4/300\n",
      "5/5 [==============================] - 1s 118ms/step - d_loss: 0.6588 - g_loss: 0.6072\n",
      "Epoch 5/300\n",
      "5/5 [==============================] - 1s 118ms/step - d_loss: 0.6587 - g_loss: 0.6257\n",
      "Epoch 6/300\n",
      "5/5 [==============================] - 1s 119ms/step - d_loss: 0.6458 - g_loss: 0.6643\n",
      "Epoch 7/300\n",
      "5/5 [==============================] - 1s 112ms/step - d_loss: 0.6250 - g_loss: 0.7178\n",
      "Epoch 8/300\n",
      "5/5 [==============================] - 1s 111ms/step - d_loss: 0.6415 - g_loss: 0.6944\n",
      "Epoch 9/300\n",
      "5/5 [==============================] - 1s 112ms/step - d_loss: 0.6828 - g_loss: 0.6327\n",
      "Epoch 10/300\n",
      "5/5 [==============================] - 1s 110ms/step - d_loss: 0.6637 - g_loss: 0.6747\n",
      "Epoch 11/300\n",
      "5/5 [==============================] - 1s 108ms/step - d_loss: 0.5519 - g_loss: 0.8243\n",
      "Epoch 12/300\n",
      "5/5 [==============================] - 1s 110ms/step - d_loss: 0.4186 - g_loss: 1.0528\n",
      "Epoch 13/300\n",
      "5/5 [==============================] - 1s 111ms/step - d_loss: 0.3801 - g_loss: 1.1373\n",
      "Epoch 14/300\n",
      "5/5 [==============================] - 1s 110ms/step - d_loss: 0.4561 - g_loss: 0.9534\n",
      "Epoch 15/300\n",
      "5/5 [==============================] - 1s 120ms/step - d_loss: 0.5919 - g_loss: 0.6376\n",
      "Epoch 16/300\n",
      "5/5 [==============================] - 1s 112ms/step - d_loss: 0.6899 - g_loss: 0.5262\n",
      "Epoch 17/300\n",
      "5/5 [==============================] - 1s 107ms/step - d_loss: 0.8870 - g_loss: 0.4050\n",
      "Epoch 18/300\n",
      "5/5 [==============================] - 1s 108ms/step - d_loss: 1.2368 - g_loss: 0.2233\n",
      "Epoch 19/300\n",
      "5/5 [==============================] - 1s 110ms/step - d_loss: 1.1828 - g_loss: 0.2777\n",
      "Epoch 20/300\n",
      "5/5 [==============================] - 1s 108ms/step - d_loss: 0.8690 - g_loss: 0.4887\n",
      "Epoch 21/300\n",
      "5/5 [==============================] - 1s 105ms/step - d_loss: 0.4783 - g_loss: 0.8584\n",
      "Epoch 22/300\n",
      "5/5 [==============================] - 1s 107ms/step - d_loss: 0.2700 - g_loss: 1.6122\n",
      "Epoch 23/300\n",
      "5/5 [==============================] - 1s 107ms/step - d_loss: 0.2096 - g_loss: 1.6723\n",
      "Epoch 24/300\n",
      "5/5 [==============================] - 1s 108ms/step - d_loss: 0.2471 - g_loss: 1.6376\n",
      "Epoch 25/300\n",
      "5/5 [==============================] - 1s 105ms/step - d_loss: 0.3419 - g_loss: 1.3071\n",
      "Epoch 26/300\n",
      "5/5 [==============================] - 1s 105ms/step - d_loss: 0.5904 - g_loss: 0.7539\n",
      "Epoch 27/300\n",
      "5/5 [==============================] - 1s 105ms/step - d_loss: 0.9390 - g_loss: 0.4340\n",
      "Epoch 28/300\n",
      "5/5 [==============================] - 1s 104ms/step - d_loss: 1.1490 - g_loss: 0.2737\n",
      "Epoch 29/300\n",
      "5/5 [==============================] - 1s 104ms/step - d_loss: 1.0792 - g_loss: 0.3690\n",
      "Epoch 30/300\n",
      "5/5 [==============================] - 1s 104ms/step - d_loss: 0.8222 - g_loss: 0.6125\n",
      "Epoch 31/300\n",
      "5/5 [==============================] - 1s 104ms/step - d_loss: 0.5766 - g_loss: 0.8465\n",
      "Epoch 32/300\n",
      "5/5 [==============================] - 1s 105ms/step - d_loss: 0.4964 - g_loss: 0.9008\n",
      "Epoch 33/300\n",
      "5/5 [==============================] - 1s 116ms/step - d_loss: 0.5007 - g_loss: 0.9136\n",
      "Epoch 34/300\n",
      "5/5 [==============================] - 1s 116ms/step - d_loss: 0.6598 - g_loss: 0.6541\n",
      "Epoch 35/300\n",
      "5/5 [==============================] - 1s 116ms/step - d_loss: 0.7779 - g_loss: 0.5619\n",
      "Epoch 36/300\n",
      "5/5 [==============================] - 1s 114ms/step - d_loss: 0.6784 - g_loss: 0.6500\n",
      "Epoch 37/300\n",
      "5/5 [==============================] - 1s 110ms/step - d_loss: 0.4532 - g_loss: 1.0607\n",
      "Epoch 38/300\n",
      "5/5 [==============================] - 1s 105ms/step - d_loss: 0.2603 - g_loss: 1.5369\n",
      "Epoch 39/300\n",
      "5/5 [==============================] - 1s 104ms/step - d_loss: 0.2552 - g_loss: 1.5396\n",
      "Epoch 40/300\n",
      "5/5 [==============================] - 1s 104ms/step - d_loss: 0.5374 - g_loss: 0.9849\n",
      "Epoch 41/300\n",
      "5/5 [==============================] - 1s 108ms/step - d_loss: 0.7268 - g_loss: 0.7849\n",
      "Epoch 42/300\n",
      "5/5 [==============================] - 1s 105ms/step - d_loss: 0.7353 - g_loss: 0.9273\n",
      "Epoch 43/300\n",
      "5/5 [==============================] - 1s 104ms/step - d_loss: 0.9016 - g_loss: 0.6012\n",
      "Epoch 44/300\n",
      "5/5 [==============================] - 1s 104ms/step - d_loss: 0.8140 - g_loss: 0.9679\n",
      "Epoch 45/300\n",
      "5/5 [==============================] - 1s 104ms/step - d_loss: 0.8356 - g_loss: 1.5869\n",
      "Epoch 46/300\n",
      "5/5 [==============================] - 1s 106ms/step - d_loss: 0.5754 - g_loss: 1.7322\n",
      "Epoch 47/300\n",
      "5/5 [==============================] - 1s 108ms/step - d_loss: 0.3151 - g_loss: 2.9368\n",
      "Epoch 48/300\n",
      "5/5 [==============================] - 1s 105ms/step - d_loss: 0.1745 - g_loss: 3.2930\n",
      "Epoch 49/300\n",
      "5/5 [==============================] - 1s 105ms/step - d_loss: 0.5741 - g_loss: 1.4967\n",
      "Epoch 50/300\n",
      "5/5 [==============================] - 1s 104ms/step - d_loss: 1.6244 - g_loss: 0.1889\n",
      "Epoch 51/300\n",
      "5/5 [==============================] - 1s 104ms/step - d_loss: 1.7748 - g_loss: 0.1211\n",
      "Epoch 52/300\n",
      "5/5 [==============================] - 1s 105ms/step - d_loss: 1.2718 - g_loss: 0.4956\n",
      "Epoch 53/300\n",
      "5/5 [==============================] - 1s 105ms/step - d_loss: 0.8847 - g_loss: 0.7563\n",
      "Epoch 54/300\n",
      "5/5 [==============================] - 1s 104ms/step - d_loss: 0.4947 - g_loss: 1.4918\n",
      "Epoch 55/300\n",
      "5/5 [==============================] - 1s 104ms/step - d_loss: 0.4293 - g_loss: 1.3810\n",
      "Epoch 56/300\n",
      "5/5 [==============================] - 1s 104ms/step - d_loss: 0.5966 - g_loss: 1.0592\n",
      "Epoch 57/300\n",
      "5/5 [==============================] - 1s 104ms/step - d_loss: 0.5673 - g_loss: 0.8589\n",
      "Epoch 58/300\n",
      "5/5 [==============================] - 1s 105ms/step - d_loss: 0.2838 - g_loss: 1.9943\n",
      "Epoch 59/300\n",
      "5/5 [==============================] - 1s 104ms/step - d_loss: 0.2635 - g_loss: 3.4619\n",
      "Epoch 60/300\n",
      "5/5 [==============================] - 1s 105ms/step - d_loss: 0.2634 - g_loss: 3.5692\n",
      "Epoch 61/300\n",
      "5/5 [==============================] - 1s 104ms/step - d_loss: 0.4723 - g_loss: 1.7652\n",
      "Epoch 62/300\n",
      "5/5 [==============================] - 1s 105ms/step - d_loss: 1.1386 - g_loss: 0.4392\n",
      "Epoch 63/300\n",
      "5/5 [==============================] - 1s 105ms/step - d_loss: 1.4348 - g_loss: 0.2300\n",
      "Epoch 64/300\n",
      "5/5 [==============================] - 1s 105ms/step - d_loss: 1.1326 - g_loss: 0.2810\n",
      "Epoch 65/300\n",
      "5/5 [==============================] - 1s 106ms/step - d_loss: 0.7911 - g_loss: 0.8455\n",
      "Epoch 66/300\n",
      "5/5 [==============================] - 1s 105ms/step - d_loss: 0.4956 - g_loss: 1.3763\n",
      "Epoch 67/300\n",
      "5/5 [==============================] - 1s 105ms/step - d_loss: 0.2928 - g_loss: 2.1647\n",
      "Epoch 68/300\n",
      "5/5 [==============================] - 1s 105ms/step - d_loss: 0.2935 - g_loss: 1.3989\n",
      "Epoch 69/300\n",
      "5/5 [==============================] - 1s 108ms/step - d_loss: 0.3127 - g_loss: 1.4983\n",
      "Epoch 70/300\n",
      "5/5 [==============================] - 1s 106ms/step - d_loss: 0.2956 - g_loss: 1.4100\n",
      "Epoch 71/300\n",
      "5/5 [==============================] - 1s 105ms/step - d_loss: 0.2922 - g_loss: 1.3293\n",
      "Epoch 72/300\n",
      "5/5 [==============================] - 1s 104ms/step - d_loss: 0.3016 - g_loss: 1.3783\n",
      "Epoch 73/300\n",
      "5/5 [==============================] - 1s 104ms/step - d_loss: 0.3392 - g_loss: 1.4062\n",
      "Epoch 74/300\n",
      "5/5 [==============================] - 1s 106ms/step - d_loss: 0.3965 - g_loss: 1.1718\n",
      "Epoch 75/300\n",
      "5/5 [==============================] - 1s 110ms/step - d_loss: 0.5620 - g_loss: 0.8333\n",
      "Epoch 76/300\n",
      "5/5 [==============================] - 1s 105ms/step - d_loss: 0.7100 - g_loss: 0.7206\n",
      "Epoch 77/300\n",
      "5/5 [==============================] - 1s 106ms/step - d_loss: 0.4923 - g_loss: 1.1075\n",
      "Epoch 78/300\n",
      "5/5 [==============================] - 1s 105ms/step - d_loss: 0.4614 - g_loss: 2.0092\n",
      "Epoch 79/300\n",
      "5/5 [==============================] - 1s 104ms/step - d_loss: 0.4268 - g_loss: 1.7753\n",
      "Epoch 80/300\n",
      "5/5 [==============================] - 1s 106ms/step - d_loss: 0.7217 - g_loss: 0.9785\n",
      "Epoch 81/300\n",
      "5/5 [==============================] - 1s 105ms/step - d_loss: 0.8724 - g_loss: 0.5996\n",
      "Epoch 82/300\n",
      "5/5 [==============================] - 1s 104ms/step - d_loss: 1.0194 - g_loss: 0.4478\n",
      "Epoch 83/300\n",
      "5/5 [==============================] - 1s 105ms/step - d_loss: 0.9790 - g_loss: 0.5083\n",
      "Epoch 84/300\n",
      "5/5 [==============================] - 1s 104ms/step - d_loss: 0.9511 - g_loss: 0.5305\n",
      "Epoch 85/300\n",
      "5/5 [==============================] - 1s 104ms/step - d_loss: 0.8733 - g_loss: 0.6626\n",
      "Epoch 86/300\n",
      "5/5 [==============================] - 1s 105ms/step - d_loss: 0.8804 - g_loss: 0.7112\n",
      "Epoch 87/300\n",
      "5/5 [==============================] - 1s 104ms/step - d_loss: 0.7258 - g_loss: 0.9621\n",
      "Epoch 88/300\n",
      "5/5 [==============================] - 1s 105ms/step - d_loss: 0.3719 - g_loss: 1.3570\n",
      "Epoch 89/300\n",
      "5/5 [==============================] - 1s 104ms/step - d_loss: 0.2178 - g_loss: 2.2775\n",
      "Epoch 90/300\n",
      "5/5 [==============================] - 1s 105ms/step - d_loss: 0.4139 - g_loss: 1.5227\n",
      "Epoch 91/300\n",
      "5/5 [==============================] - 1s 105ms/step - d_loss: 0.6657 - g_loss: 0.9049\n",
      "Epoch 92/300\n",
      "5/5 [==============================] - 1s 104ms/step - d_loss: 0.7269 - g_loss: 0.7380\n",
      "Epoch 93/300\n",
      "5/5 [==============================] - 1s 105ms/step - d_loss: 0.7147 - g_loss: 0.7906\n",
      "Epoch 94/300\n",
      "5/5 [==============================] - 1s 104ms/step - d_loss: 0.7309 - g_loss: 0.7522\n",
      "Epoch 95/300\n",
      "5/5 [==============================] - 1s 105ms/step - d_loss: 0.6908 - g_loss: 0.8231\n",
      "Epoch 96/300\n",
      "5/5 [==============================] - 1s 105ms/step - d_loss: 0.6911 - g_loss: 0.8078\n",
      "Epoch 97/300\n",
      "5/5 [==============================] - 1s 104ms/step - d_loss: 0.7068 - g_loss: 0.7637\n",
      "Epoch 98/300\n",
      "5/5 [==============================] - 1s 105ms/step - d_loss: 0.6888 - g_loss: 0.8218\n",
      "Epoch 99/300\n",
      "5/5 [==============================] - 1s 104ms/step - d_loss: 0.6525 - g_loss: 0.9127\n",
      "Epoch 100/300\n",
      "5/5 [==============================] - 1s 106ms/step - d_loss: 0.6482 - g_loss: 0.9551\n",
      "Epoch 101/300\n",
      "5/5 [==============================] - 1s 106ms/step - d_loss: 0.6704 - g_loss: 0.9258\n",
      "Epoch 102/300\n",
      "5/5 [==============================] - 1s 104ms/step - d_loss: 0.6728 - g_loss: 0.8580\n",
      "Epoch 103/300\n",
      "5/5 [==============================] - 1s 105ms/step - d_loss: 0.6438 - g_loss: 0.8848\n",
      "Epoch 104/300\n",
      "5/5 [==============================] - 1s 104ms/step - d_loss: 0.6236 - g_loss: 0.8812\n",
      "Epoch 105/300\n",
      "5/5 [==============================] - 1s 105ms/step - d_loss: 0.6209 - g_loss: 0.8649\n",
      "Epoch 106/300\n",
      "5/5 [==============================] - 1s 106ms/step - d_loss: 0.6025 - g_loss: 0.8878\n",
      "Epoch 107/300\n",
      "5/5 [==============================] - 1s 105ms/step - d_loss: 0.5996 - g_loss: 0.8852\n",
      "Epoch 108/300\n",
      "5/5 [==============================] - 1s 105ms/step - d_loss: 0.5917 - g_loss: 0.8991\n",
      "Epoch 109/300\n",
      "5/5 [==============================] - 1s 104ms/step - d_loss: 0.5927 - g_loss: 0.8987\n",
      "Epoch 110/300\n",
      "5/5 [==============================] - 1s 105ms/step - d_loss: 0.5937 - g_loss: 0.9002\n",
      "Epoch 111/300\n",
      "5/5 [==============================] - 1s 106ms/step - d_loss: 0.5940 - g_loss: 0.9420\n",
      "Epoch 112/300\n",
      "5/5 [==============================] - 1s 110ms/step - d_loss: 0.5798 - g_loss: 0.9513\n",
      "Epoch 113/300\n",
      "5/5 [==============================] - 1s 106ms/step - d_loss: 0.5784 - g_loss: 0.9410\n",
      "Epoch 114/300\n",
      "5/5 [==============================] - 1s 104ms/step - d_loss: 0.5850 - g_loss: 0.9833\n",
      "Epoch 115/300\n",
      "5/5 [==============================] - 1s 104ms/step - d_loss: 0.5630 - g_loss: 1.0458\n",
      "Epoch 116/300\n",
      "5/5 [==============================] - 1s 104ms/step - d_loss: 0.5512 - g_loss: 1.0108\n",
      "Epoch 117/300\n",
      "5/5 [==============================] - 1s 105ms/step - d_loss: 0.5339 - g_loss: 1.0276\n",
      "Epoch 118/300\n",
      "5/5 [==============================] - 1s 109ms/step - d_loss: 0.5305 - g_loss: 1.0407\n",
      "Epoch 119/300\n",
      "5/5 [==============================] - 1s 105ms/step - d_loss: 0.5126 - g_loss: 1.0426\n",
      "Epoch 120/300\n",
      "5/5 [==============================] - 1s 106ms/step - d_loss: 0.5308 - g_loss: 0.9955\n",
      "Epoch 121/300\n",
      "5/5 [==============================] - 1s 106ms/step - d_loss: 0.5063 - g_loss: 1.0264\n",
      "Epoch 122/300\n",
      "5/5 [==============================] - 1s 105ms/step - d_loss: 0.4983 - g_loss: 1.0725\n",
      "Epoch 123/300\n",
      "5/5 [==============================] - 1s 104ms/step - d_loss: 0.4855 - g_loss: 1.0803\n",
      "Epoch 124/300\n",
      "5/5 [==============================] - 1s 104ms/step - d_loss: 0.4710 - g_loss: 1.1339\n",
      "Epoch 125/300\n",
      "5/5 [==============================] - 1s 104ms/step - d_loss: 0.4712 - g_loss: 1.0686\n",
      "Epoch 126/300\n",
      "5/5 [==============================] - 1s 106ms/step - d_loss: 0.4471 - g_loss: 1.1823\n",
      "Epoch 127/300\n",
      "5/5 [==============================] - 1s 106ms/step - d_loss: 0.4713 - g_loss: 1.1087\n",
      "Epoch 128/300\n",
      "5/5 [==============================] - 1s 109ms/step - d_loss: 0.4470 - g_loss: 1.1563\n",
      "Epoch 129/300\n",
      "5/5 [==============================] - 1s 105ms/step - d_loss: 0.4558 - g_loss: 1.1441\n",
      "Epoch 130/300\n",
      "5/5 [==============================] - 1s 104ms/step - d_loss: 0.4501 - g_loss: 1.1182\n",
      "Epoch 131/300\n",
      "5/5 [==============================] - 1s 104ms/step - d_loss: 0.4624 - g_loss: 1.3758\n",
      "Epoch 132/300\n",
      "5/5 [==============================] - 1s 104ms/step - d_loss: 0.4934 - g_loss: 1.3394\n",
      "Epoch 133/300\n",
      "5/5 [==============================] - 1s 105ms/step - d_loss: 0.4510 - g_loss: 1.2254\n",
      "Epoch 134/300\n",
      "5/5 [==============================] - 1s 105ms/step - d_loss: 0.4367 - g_loss: 1.2080\n",
      "Epoch 135/300\n",
      "5/5 [==============================] - 1s 104ms/step - d_loss: 0.4381 - g_loss: 1.2561\n",
      "Epoch 136/300\n",
      "5/5 [==============================] - 1s 104ms/step - d_loss: 0.4133 - g_loss: 1.3170\n",
      "Epoch 137/300\n",
      "5/5 [==============================] - 1s 104ms/step - d_loss: 0.3912 - g_loss: 1.2941\n",
      "Epoch 138/300\n",
      "5/5 [==============================] - 1s 104ms/step - d_loss: 0.3812 - g_loss: 1.4335\n",
      "Epoch 139/300\n",
      "5/5 [==============================] - 1s 105ms/step - d_loss: 0.3921 - g_loss: 1.2856\n",
      "Epoch 140/300\n",
      "5/5 [==============================] - 1s 104ms/step - d_loss: 0.3880 - g_loss: 1.1882\n",
      "Epoch 141/300\n",
      "5/5 [==============================] - 1s 105ms/step - d_loss: 0.4080 - g_loss: 1.5094\n",
      "Epoch 142/300\n",
      "5/5 [==============================] - 1s 104ms/step - d_loss: 0.3804 - g_loss: 1.4228\n",
      "Epoch 143/300\n",
      "5/5 [==============================] - 1s 105ms/step - d_loss: 0.3563 - g_loss: 1.5975\n",
      "Epoch 144/300\n",
      "5/5 [==============================] - 1s 105ms/step - d_loss: 0.3522 - g_loss: 1.5220\n",
      "Epoch 145/300\n",
      "5/5 [==============================] - 1s 104ms/step - d_loss: 0.3889 - g_loss: 1.3920\n",
      "Epoch 146/300\n",
      "5/5 [==============================] - 1s 105ms/step - d_loss: 0.3437 - g_loss: 1.4706\n",
      "Epoch 147/300\n",
      "5/5 [==============================] - 1s 104ms/step - d_loss: 0.3188 - g_loss: 1.5002\n",
      "Epoch 148/300\n",
      "5/5 [==============================] - 1s 105ms/step - d_loss: 0.3563 - g_loss: 1.3890\n",
      "Epoch 149/300\n",
      "5/5 [==============================] - 1s 104ms/step - d_loss: 0.3644 - g_loss: 1.3560\n",
      "Epoch 150/300\n",
      "5/5 [==============================] - 1s 106ms/step - d_loss: 0.3865 - g_loss: 1.6156\n",
      "Epoch 151/300\n",
      "5/5 [==============================] - 1s 109ms/step - d_loss: 0.3281 - g_loss: 1.7775\n",
      "Epoch 152/300\n",
      "5/5 [==============================] - 1s 105ms/step - d_loss: 0.3821 - g_loss: 1.6113\n",
      "Epoch 153/300\n",
      "5/5 [==============================] - 1s 104ms/step - d_loss: 0.3633 - g_loss: 1.3630\n",
      "Epoch 154/300\n",
      "5/5 [==============================] - 1s 106ms/step - d_loss: 0.4146 - g_loss: 1.6893\n",
      "Epoch 155/300\n",
      "5/5 [==============================] - 1s 106ms/step - d_loss: 0.3390 - g_loss: 1.5913\n",
      "Epoch 156/300\n",
      "5/5 [==============================] - 1s 109ms/step - d_loss: 0.2870 - g_loss: 1.7344\n",
      "Epoch 157/300\n",
      "5/5 [==============================] - 1s 105ms/step - d_loss: 0.2994 - g_loss: 1.6488\n",
      "Epoch 158/300\n",
      "5/5 [==============================] - 1s 105ms/step - d_loss: 0.2862 - g_loss: 1.5679\n",
      "Epoch 159/300\n",
      "5/5 [==============================] - 1s 106ms/step - d_loss: 0.2941 - g_loss: 1.6209\n",
      "Epoch 160/300\n",
      "5/5 [==============================] - 1s 105ms/step - d_loss: 0.2759 - g_loss: 1.7491\n",
      "Epoch 161/300\n",
      "5/5 [==============================] - 1s 108ms/step - d_loss: 0.2772 - g_loss: 1.6261\n",
      "Epoch 162/300\n",
      "5/5 [==============================] - 1s 105ms/step - d_loss: 0.2880 - g_loss: 1.6092\n",
      "Epoch 163/300\n",
      "5/5 [==============================] - 1s 105ms/step - d_loss: 0.3335 - g_loss: 1.8964\n",
      "Epoch 164/300\n",
      "5/5 [==============================] - 1s 106ms/step - d_loss: 0.3306 - g_loss: 1.7966\n",
      "Epoch 165/300\n",
      "5/5 [==============================] - 1s 105ms/step - d_loss: 0.2849 - g_loss: 1.6342\n",
      "Epoch 166/300\n",
      "5/5 [==============================] - 1s 109ms/step - d_loss: 0.3167 - g_loss: 1.8556\n",
      "Epoch 167/300\n",
      "5/5 [==============================] - 1s 105ms/step - d_loss: 0.2902 - g_loss: 1.7774\n",
      "Epoch 168/300\n",
      "5/5 [==============================] - 1s 105ms/step - d_loss: 0.2720 - g_loss: 1.6818\n",
      "Epoch 169/300\n",
      "5/5 [==============================] - 1s 106ms/step - d_loss: 0.2630 - g_loss: 1.7916\n",
      "Epoch 170/300\n",
      "5/5 [==============================] - 1s 105ms/step - d_loss: 0.2322 - g_loss: 2.0792\n",
      "Epoch 171/300\n",
      "5/5 [==============================] - 1s 108ms/step - d_loss: 0.2546 - g_loss: 2.0922\n",
      "Epoch 172/300\n",
      "5/5 [==============================] - 1s 104ms/step - d_loss: 0.2717 - g_loss: 1.7793\n",
      "Epoch 173/300\n",
      "5/5 [==============================] - 1s 106ms/step - d_loss: 0.2318 - g_loss: 1.8682\n",
      "Epoch 174/300\n",
      "5/5 [==============================] - 1s 105ms/step - d_loss: 0.2266 - g_loss: 1.9139\n",
      "Epoch 175/300\n",
      "5/5 [==============================] - 1s 106ms/step - d_loss: 0.2681 - g_loss: 1.7354\n",
      "Epoch 176/300\n",
      "5/5 [==============================] - 1s 108ms/step - d_loss: 0.3109 - g_loss: 1.9814\n",
      "Epoch 177/300\n",
      "5/5 [==============================] - 1s 105ms/step - d_loss: 0.2847 - g_loss: 2.1188\n",
      "Epoch 178/300\n",
      "5/5 [==============================] - 1s 106ms/step - d_loss: 0.2390 - g_loss: 2.1367\n",
      "Epoch 179/300\n",
      "5/5 [==============================] - 1s 104ms/step - d_loss: 0.2226 - g_loss: 2.3372\n",
      "Epoch 180/300\n",
      "5/5 [==============================] - 1s 104ms/step - d_loss: 0.2730 - g_loss: 2.5611\n",
      "Epoch 181/300\n",
      "5/5 [==============================] - 1s 106ms/step - d_loss: 0.4113 - g_loss: 2.5348\n",
      "Epoch 182/300\n",
      "5/5 [==============================] - 1s 105ms/step - d_loss: 0.5236 - g_loss: 2.1817\n",
      "Epoch 183/300\n",
      "5/5 [==============================] - 1s 104ms/step - d_loss: 0.4244 - g_loss: 2.1328\n",
      "Epoch 184/300\n",
      "5/5 [==============================] - 1s 104ms/step - d_loss: 0.3163 - g_loss: 2.0880\n",
      "Epoch 185/300\n",
      "5/5 [==============================] - 1s 104ms/step - d_loss: 0.2773 - g_loss: 2.0802\n",
      "Epoch 186/300\n",
      "5/5 [==============================] - 1s 104ms/step - d_loss: 0.2633 - g_loss: 2.1468\n",
      "Epoch 187/300\n",
      "5/5 [==============================] - 1s 105ms/step - d_loss: 0.2435 - g_loss: 2.1354\n",
      "Epoch 188/300\n",
      "5/5 [==============================] - 1s 109ms/step - d_loss: 0.1954 - g_loss: 2.1477\n",
      "Epoch 189/300\n",
      "5/5 [==============================] - 1s 105ms/step - d_loss: 0.2016 - g_loss: 2.0901\n",
      "Epoch 190/300\n",
      "5/5 [==============================] - 1s 104ms/step - d_loss: 0.1947 - g_loss: 2.0512\n",
      "Epoch 191/300\n",
      "5/5 [==============================] - 1s 105ms/step - d_loss: 0.1974 - g_loss: 2.1138\n",
      "Epoch 192/300\n",
      "5/5 [==============================] - 1s 104ms/step - d_loss: 0.2048 - g_loss: 2.2087\n",
      "Epoch 193/300\n",
      "5/5 [==============================] - 1s 104ms/step - d_loss: 0.2062 - g_loss: 2.2216\n",
      "Epoch 194/300\n",
      "5/5 [==============================] - 1s 106ms/step - d_loss: 0.1854 - g_loss: 2.2165\n",
      "Epoch 195/300\n",
      "5/5 [==============================] - 1s 104ms/step - d_loss: 0.2230 - g_loss: 2.1121\n",
      "Epoch 196/300\n",
      "5/5 [==============================] - 1s 105ms/step - d_loss: 0.1905 - g_loss: 2.1904\n",
      "Epoch 197/300\n",
      "5/5 [==============================] - 1s 104ms/step - d_loss: 0.1715 - g_loss: 2.2377\n",
      "Epoch 198/300\n",
      "5/5 [==============================] - 1s 104ms/step - d_loss: 0.1811 - g_loss: 2.2578\n",
      "Epoch 199/300\n",
      "5/5 [==============================] - 1s 105ms/step - d_loss: 0.1882 - g_loss: 2.2009\n",
      "Epoch 200/300\n",
      "5/5 [==============================] - 1s 105ms/step - d_loss: 0.1543 - g_loss: 2.3657\n",
      "Epoch 201/300\n",
      "5/5 [==============================] - 1s 105ms/step - d_loss: 0.1968 - g_loss: 2.2037\n",
      "Epoch 202/300\n",
      "5/5 [==============================] - 1s 105ms/step - d_loss: 0.1984 - g_loss: 2.0551\n",
      "Epoch 203/300\n",
      "5/5 [==============================] - 1s 104ms/step - d_loss: 0.2060 - g_loss: 2.2789\n",
      "Epoch 204/300\n",
      "5/5 [==============================] - 1s 105ms/step - d_loss: 0.1969 - g_loss: 2.5816\n",
      "Epoch 205/300\n",
      "5/5 [==============================] - 1s 104ms/step - d_loss: 0.1861 - g_loss: 2.1365\n",
      "Epoch 206/300\n",
      "5/5 [==============================] - 1s 105ms/step - d_loss: 0.2389 - g_loss: 2.3294\n",
      "Epoch 207/300\n",
      "5/5 [==============================] - 1s 105ms/step - d_loss: 0.2972 - g_loss: 2.5363\n",
      "Epoch 208/300\n",
      "5/5 [==============================] - 1s 105ms/step - d_loss: 0.2792 - g_loss: 2.3245\n",
      "Epoch 209/300\n",
      "5/5 [==============================] - 1s 105ms/step - d_loss: 0.2171 - g_loss: 2.5655\n",
      "Epoch 210/300\n",
      "5/5 [==============================] - 1s 104ms/step - d_loss: 0.1886 - g_loss: 2.4140\n",
      "Epoch 211/300\n",
      "5/5 [==============================] - 1s 105ms/step - d_loss: 0.2279 - g_loss: 2.7292\n",
      "Epoch 212/300\n",
      "5/5 [==============================] - 1s 105ms/step - d_loss: 0.4419 - g_loss: 2.5213\n",
      "Epoch 213/300\n",
      "5/5 [==============================] - 1s 104ms/step - d_loss: 0.1797 - g_loss: 2.3250\n",
      "Epoch 214/300\n",
      "5/5 [==============================] - 1s 105ms/step - d_loss: 0.2004 - g_loss: 2.3299\n",
      "Epoch 215/300\n",
      "5/5 [==============================] - 1s 104ms/step - d_loss: 0.1718 - g_loss: 2.4488\n",
      "Epoch 216/300\n",
      "5/5 [==============================] - 1s 105ms/step - d_loss: 0.1619 - g_loss: 2.3955\n",
      "Epoch 217/300\n",
      "5/5 [==============================] - 1s 105ms/step - d_loss: 0.1967 - g_loss: 2.2935\n",
      "Epoch 218/300\n",
      "5/5 [==============================] - 1s 104ms/step - d_loss: 0.1942 - g_loss: 2.7983\n",
      "Epoch 219/300\n",
      "5/5 [==============================] - 1s 105ms/step - d_loss: 0.1887 - g_loss: 2.1158\n",
      "Epoch 220/300\n",
      "5/5 [==============================] - 1s 104ms/step - d_loss: 0.2186 - g_loss: 2.6552\n",
      "Epoch 221/300\n",
      "5/5 [==============================] - 1s 105ms/step - d_loss: 0.1675 - g_loss: 3.1114\n",
      "Epoch 222/300\n",
      "5/5 [==============================] - 1s 105ms/step - d_loss: 0.2158 - g_loss: 2.3198\n",
      "Epoch 223/300\n",
      "5/5 [==============================] - 1s 104ms/step - d_loss: 0.1561 - g_loss: 2.4349\n",
      "Epoch 224/300\n",
      "5/5 [==============================] - 1s 105ms/step - d_loss: 0.1866 - g_loss: 2.5097\n",
      "Epoch 225/300\n",
      "5/5 [==============================] - 1s 104ms/step - d_loss: 0.1766 - g_loss: 2.6367\n",
      "Epoch 226/300\n",
      "5/5 [==============================] - 1s 105ms/step - d_loss: 0.1700 - g_loss: 2.8870\n",
      "Epoch 227/300\n",
      "5/5 [==============================] - 1s 105ms/step - d_loss: 0.1569 - g_loss: 2.5614\n",
      "Epoch 228/300\n",
      "5/5 [==============================] - 1s 104ms/step - d_loss: 0.1314 - g_loss: 2.9440\n",
      "Epoch 229/300\n",
      "5/5 [==============================] - 1s 105ms/step - d_loss: 0.1830 - g_loss: 2.4251\n",
      "Epoch 230/300\n",
      "5/5 [==============================] - 1s 104ms/step - d_loss: 0.1391 - g_loss: 2.6548\n",
      "Epoch 231/300\n",
      "5/5 [==============================] - 1s 105ms/step - d_loss: 0.1511 - g_loss: 2.6500\n",
      "Epoch 232/300\n",
      "5/5 [==============================] - 1s 106ms/step - d_loss: 0.1511 - g_loss: 2.8104\n",
      "Epoch 233/300\n",
      "5/5 [==============================] - 1s 104ms/step - d_loss: 0.1564 - g_loss: 2.7797\n",
      "Epoch 234/300\n",
      "5/5 [==============================] - 1s 105ms/step - d_loss: 0.1366 - g_loss: 2.5801\n",
      "Epoch 235/300\n",
      "5/5 [==============================] - 1s 104ms/step - d_loss: 0.1266 - g_loss: 2.7509\n",
      "Epoch 236/300\n",
      "5/5 [==============================] - 1s 105ms/step - d_loss: 0.1453 - g_loss: 2.6401\n",
      "Epoch 237/300\n",
      "5/5 [==============================] - 1s 106ms/step - d_loss: 0.1801 - g_loss: 2.6130\n",
      "Epoch 238/300\n",
      "5/5 [==============================] - 1s 104ms/step - d_loss: 0.1529 - g_loss: 2.7754\n",
      "Epoch 239/300\n",
      "5/5 [==============================] - 1s 105ms/step - d_loss: 0.1287 - g_loss: 2.6623\n",
      "Epoch 240/300\n",
      "5/5 [==============================] - 1s 104ms/step - d_loss: 0.1255 - g_loss: 2.8846\n",
      "Epoch 241/300\n",
      "5/5 [==============================] - 1s 106ms/step - d_loss: 0.1264 - g_loss: 2.8563\n",
      "Epoch 242/300\n",
      "5/5 [==============================] - 1s 106ms/step - d_loss: 0.1755 - g_loss: 2.7300\n",
      "Epoch 243/300\n",
      "5/5 [==============================] - 1s 104ms/step - d_loss: 0.1417 - g_loss: 2.8226\n",
      "Epoch 244/300\n",
      "5/5 [==============================] - 1s 105ms/step - d_loss: 0.1804 - g_loss: 3.4043\n",
      "Epoch 245/300\n",
      "5/5 [==============================] - 1s 104ms/step - d_loss: 0.1436 - g_loss: 2.5435\n",
      "Epoch 246/300\n",
      "5/5 [==============================] - 1s 105ms/step - d_loss: 0.2164 - g_loss: 2.6865\n",
      "Epoch 247/300\n",
      "5/5 [==============================] - 1s 106ms/step - d_loss: 0.3335 - g_loss: 3.4129\n",
      "Epoch 248/300\n",
      "5/5 [==============================] - 1s 109ms/step - d_loss: 0.3397 - g_loss: 3.4611\n",
      "Epoch 249/300\n",
      "5/5 [==============================] - 1s 106ms/step - d_loss: 0.1988 - g_loss: 2.9424\n",
      "Epoch 250/300\n",
      "5/5 [==============================] - 1s 104ms/step - d_loss: 0.4452 - g_loss: 2.6243\n",
      "Epoch 251/300\n",
      "5/5 [==============================] - 1s 104ms/step - d_loss: 0.3553 - g_loss: 3.2035\n",
      "Epoch 252/300\n",
      "5/5 [==============================] - 1s 106ms/step - d_loss: 0.2456 - g_loss: 3.4718\n",
      "Epoch 253/300\n",
      "5/5 [==============================] - 1s 105ms/step - d_loss: 0.1515 - g_loss: 2.7172\n",
      "Epoch 254/300\n",
      "5/5 [==============================] - 1s 104ms/step - d_loss: 0.1864 - g_loss: 2.5258\n",
      "Epoch 255/300\n",
      "5/5 [==============================] - 1s 104ms/step - d_loss: 0.1445 - g_loss: 2.9233\n",
      "Epoch 256/300\n",
      "5/5 [==============================] - 1s 105ms/step - d_loss: 0.1469 - g_loss: 2.8635\n",
      "Epoch 257/300\n",
      "5/5 [==============================] - 1s 104ms/step - d_loss: 0.1299 - g_loss: 2.5876\n",
      "Epoch 258/300\n",
      "5/5 [==============================] - 1s 105ms/step - d_loss: 0.1393 - g_loss: 2.7021\n",
      "Epoch 259/300\n",
      "5/5 [==============================] - 1s 104ms/step - d_loss: 0.1674 - g_loss: 2.7019\n",
      "Epoch 260/300\n",
      "5/5 [==============================] - 1s 105ms/step - d_loss: 0.1949 - g_loss: 3.5537\n",
      "Epoch 261/300\n",
      "5/5 [==============================] - 1s 104ms/step - d_loss: 0.1470 - g_loss: 2.7876\n",
      "Epoch 262/300\n",
      "5/5 [==============================] - 1s 106ms/step - d_loss: 0.1460 - g_loss: 2.6186\n",
      "Epoch 263/300\n",
      "5/5 [==============================] - 1s 106ms/step - d_loss: 0.1591 - g_loss: 2.8750\n",
      "Epoch 264/300\n",
      "5/5 [==============================] - 1s 105ms/step - d_loss: 0.1653 - g_loss: 3.3228\n",
      "Epoch 265/300\n",
      "5/5 [==============================] - 1s 105ms/step - d_loss: 0.1769 - g_loss: 3.4889\n",
      "Epoch 266/300\n",
      "5/5 [==============================] - 1s 104ms/step - d_loss: 0.1674 - g_loss: 2.6703\n",
      "Epoch 267/300\n",
      "5/5 [==============================] - 1s 105ms/step - d_loss: 0.1200 - g_loss: 2.8211\n",
      "Epoch 268/300\n",
      "5/5 [==============================] - 1s 109ms/step - d_loss: 0.1259 - g_loss: 2.9083\n",
      "Epoch 269/300\n",
      "5/5 [==============================] - 1s 105ms/step - d_loss: 0.1133 - g_loss: 3.5344\n",
      "Epoch 270/300\n",
      "5/5 [==============================] - 1s 107ms/step - d_loss: 0.1491 - g_loss: 2.8357\n",
      "Epoch 271/300\n",
      "5/5 [==============================] - 1s 107ms/step - d_loss: 0.1588 - g_loss: 3.0255\n",
      "Epoch 272/300\n",
      "5/5 [==============================] - 1s 107ms/step - d_loss: 0.1290 - g_loss: 3.6442\n",
      "Epoch 273/300\n",
      "5/5 [==============================] - 1s 105ms/step - d_loss: 0.1323 - g_loss: 2.7679\n",
      "Epoch 274/300\n",
      "5/5 [==============================] - 1s 105ms/step - d_loss: 0.1084 - g_loss: 3.0603\n",
      "Epoch 275/300\n",
      "5/5 [==============================] - 1s 107ms/step - d_loss: 0.0989 - g_loss: 3.4776\n",
      "Epoch 276/300\n",
      "5/5 [==============================] - 1s 107ms/step - d_loss: 0.1587 - g_loss: 2.6632\n",
      "Epoch 277/300\n",
      "5/5 [==============================] - 1s 106ms/step - d_loss: 0.1675 - g_loss: 4.0876\n",
      "Epoch 278/300\n",
      "5/5 [==============================] - 1s 107ms/step - d_loss: 0.1401 - g_loss: 2.5543\n",
      "Epoch 279/300\n",
      "5/5 [==============================] - 1s 113ms/step - d_loss: 0.1670 - g_loss: 3.1300\n",
      "Epoch 280/300\n",
      "5/5 [==============================] - 1s 108ms/step - d_loss: 0.1111 - g_loss: 3.3535\n",
      "Epoch 281/300\n",
      "5/5 [==============================] - 1s 108ms/step - d_loss: 0.1055 - g_loss: 3.3509\n",
      "Epoch 282/300\n",
      "5/5 [==============================] - 1s 106ms/step - d_loss: 0.1168 - g_loss: 3.1535\n",
      "Epoch 283/300\n",
      "5/5 [==============================] - 1s 106ms/step - d_loss: 0.1135 - g_loss: 3.7979\n",
      "Epoch 284/300\n",
      "5/5 [==============================] - 1s 106ms/step - d_loss: 0.1111 - g_loss: 2.8612\n",
      "Epoch 285/300\n",
      "5/5 [==============================] - 1s 110ms/step - d_loss: 0.1063 - g_loss: 3.5738\n",
      "Epoch 286/300\n",
      "5/5 [==============================] - 1s 106ms/step - d_loss: 0.1434 - g_loss: 3.1440\n",
      "Epoch 287/300\n",
      "5/5 [==============================] - 1s 106ms/step - d_loss: 0.1083 - g_loss: 3.3033\n",
      "Epoch 288/300\n",
      "5/5 [==============================] - 1s 105ms/step - d_loss: 0.1021 - g_loss: 3.3403\n",
      "Epoch 289/300\n",
      "5/5 [==============================] - 1s 106ms/step - d_loss: 0.1025 - g_loss: 3.2483\n",
      "Epoch 290/300\n",
      "5/5 [==============================] - 1s 105ms/step - d_loss: 0.1148 - g_loss: 3.1755\n",
      "Epoch 291/300\n",
      "5/5 [==============================] - 1s 105ms/step - d_loss: 0.0981 - g_loss: 3.6320\n",
      "Epoch 292/300\n",
      "5/5 [==============================] - 1s 105ms/step - d_loss: 0.1069 - g_loss: 2.9735\n",
      "Epoch 293/300\n",
      "5/5 [==============================] - 1s 104ms/step - d_loss: 0.1359 - g_loss: 3.4021\n",
      "Epoch 294/300\n",
      "5/5 [==============================] - 1s 104ms/step - d_loss: 0.1108 - g_loss: 3.5097\n",
      "Epoch 295/300\n",
      "5/5 [==============================] - 1s 106ms/step - d_loss: 0.1489 - g_loss: 2.9558\n",
      "Epoch 296/300\n",
      "5/5 [==============================] - 1s 104ms/step - d_loss: 0.1254 - g_loss: 3.7601\n",
      "Epoch 297/300\n",
      "5/5 [==============================] - 1s 105ms/step - d_loss: 0.1035 - g_loss: 3.3942\n",
      "Epoch 298/300\n",
      "5/5 [==============================] - 1s 105ms/step - d_loss: 0.1271 - g_loss: 3.2804\n",
      "Epoch 299/300\n",
      "5/5 [==============================] - 1s 106ms/step - d_loss: 0.1041 - g_loss: 3.4946\n",
      "Epoch 300/300\n",
      "5/5 [==============================] - 1s 105ms/step - d_loss: 0.0995 - g_loss: 3.5582\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x21deda99b48>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "discriminator = keras.Sequential(\n",
    "    [\n",
    "        keras.Input(shape=(64, 64, 3)),\n",
    "        layers.Conv2D(64, kernel_size=4, strides=2, padding=\"same\"),\n",
    "        layers.LeakyReLU(alpha=0.2),\n",
    "        layers.Conv2D(128, kernel_size=4, strides=2, padding=\"same\"),\n",
    "        layers.LeakyReLU(alpha=0.2),\n",
    "        layers.Conv2D(128, kernel_size=4, strides=2, padding=\"same\"),\n",
    "        layers.LeakyReLU(alpha=0.2),\n",
    "        layers.Flatten(),\n",
    "        layers.Dropout(0.2),\n",
    "        layers.Dense(1, activation=\"sigmoid\"),\n",
    "    ],\n",
    "    name=\"discriminator\",\n",
    ")\n",
    "discriminator.summary()\n",
    "\n",
    "latent_dim = 128\n",
    "\n",
    "generator = keras.Sequential(\n",
    "    [\n",
    "        keras.Input(shape=(latent_dim,)),\n",
    "        layers.Dense(8 * 8 * 128),\n",
    "        layers.Reshape((8, 8, 128)),\n",
    "        layers.Conv2DTranspose(128, kernel_size=4, strides=2, padding=\"same\"),\n",
    "        layers.LeakyReLU(alpha=0.2),\n",
    "        layers.Conv2DTranspose(256, kernel_size=4, strides=2, padding=\"same\"),\n",
    "        layers.LeakyReLU(alpha=0.2),\n",
    "        layers.Conv2DTranspose(512, kernel_size=4, strides=2, padding=\"same\"),\n",
    "        layers.LeakyReLU(alpha=0.2),\n",
    "        layers.Conv2D(3, kernel_size=5, padding=\"same\", activation=\"sigmoid\"),\n",
    "    ],\n",
    "    name=\"generator\",\n",
    ")\n",
    "generator.summary()\n",
    "\n",
    "\n",
    "class GAN(keras.Model):\n",
    "    def __init__(self, discriminator, generator, latent_dim):\n",
    "        super(GAN, self).__init__()\n",
    "        self.discriminator = discriminator\n",
    "        self.generator = generator\n",
    "        self.latent_dim = latent_dim\n",
    "\n",
    "    def compile(self, d_optimizer, g_optimizer, loss_fn):\n",
    "        super(GAN, self).compile()\n",
    "        self.d_optimizer = d_optimizer\n",
    "        self.g_optimizer = g_optimizer\n",
    "        self.loss_fn = loss_fn\n",
    "        self.d_loss_metric = keras.metrics.Mean(name=\"d_loss\")\n",
    "        self.g_loss_metric = keras.metrics.Mean(name=\"g_loss\")\n",
    "\n",
    "    @property\n",
    "    def metrics(self):\n",
    "        return [self.d_loss_metric, self.g_loss_metric]\n",
    "\n",
    "    def train_step(self, real_images):\n",
    "\n",
    "        batch_size = tf.shape(real_images)[0]\n",
    "        random_latent_vectors = tf.random.normal(shape=(batch_size, self.latent_dim))\n",
    "\n",
    "\n",
    "        generated_images = self.generator(random_latent_vectors)\n",
    "\n",
    "\n",
    "        combined_images = tf.concat([generated_images, real_images], axis=0)\n",
    "\n",
    "\n",
    "        labels = tf.concat(\n",
    "            [tf.ones((batch_size, 1)), tf.zeros((batch_size, 1))], axis=0\n",
    "        )\n",
    "\n",
    "        labels += 0.05 * tf.random.uniform(tf.shape(labels))\n",
    "\n",
    "\n",
    "        with tf.GradientTape() as tape:\n",
    "            predictions = self.discriminator(combined_images)\n",
    "            d_loss = self.loss_fn(labels, predictions)\n",
    "        grads = tape.gradient(d_loss, self.discriminator.trainable_weights)\n",
    "        self.d_optimizer.apply_gradients(\n",
    "            zip(grads, self.discriminator.trainable_weights)\n",
    "        )\n",
    "\n",
    "        random_latent_vectors = tf.random.normal(shape=(batch_size, self.latent_dim))\n",
    "        misleading_labels = tf.zeros((batch_size, 1))\n",
    "\n",
    "        with tf.GradientTape() as tape:\n",
    "            predictions = self.discriminator(self.generator(random_latent_vectors))\n",
    "            g_loss = self.loss_fn(misleading_labels, predictions)\n",
    "        grads = tape.gradient(g_loss, self.generator.trainable_weights)\n",
    "        self.g_optimizer.apply_gradients(zip(grads, self.generator.trainable_weights))\n",
    "\n",
    "\n",
    "        self.d_loss_metric.update_state(d_loss)\n",
    "        self.g_loss_metric.update_state(g_loss)\n",
    "        return {\n",
    "            \"d_loss\": self.d_loss_metric.result(),\n",
    "            \"g_loss\": self.g_loss_metric.result(),\n",
    "        }\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "## Create a callback that periodically saves generated images\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "class GANMonitor(keras.callbacks.Callback):\n",
    "    def __init__(self, num_img=3, latent_dim=128):\n",
    "        self.num_img = num_img\n",
    "        self.latent_dim = latent_dim\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        random_latent_vectors = tf.random.normal(shape=(self.num_img, self.latent_dim))\n",
    "        generated_images = self.model.generator(random_latent_vectors)\n",
    "        generated_images *= 255\n",
    "        generated_images.numpy()\n",
    "        for i in range(self.num_img):\n",
    "            img = keras.preprocessing.image.array_to_img(generated_images[i])\n",
    "            img.save(\"gen/generated_img_%03d_%d.png\" % (epoch, i))\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "## Train the end-to-end model\n",
    "\"\"\"\n",
    "filepath=\"models/weights-improvement-{epoch:02d}-{g_loss:.2f}.tf\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='g_loss', verbose=1, save_best_only=True, mode='max')\n",
    "callbacks_list = [checkpoint]\n",
    "\n",
    "\n",
    "epochs = 300  \n",
    "\n",
    "gan = GAN(discriminator=discriminator, generator=generator, latent_dim=latent_dim)\n",
    "gan.compile(\n",
    "    d_optimizer=keras.optimizers.Adam(learning_rate=0.0001),\n",
    "    g_optimizer=keras.optimizers.Adam(learning_rate=0.0001),\n",
    "    loss_fn=keras.losses.BinaryCrossentropy(),\n",
    ")\n",
    "\n",
    "gan.fit(\n",
    "    dataset, epochs=epochs, callbacks=[GANMonitor(num_img=10, latent_dim=latent_dim)]\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b63ca20dba7b8d747f2eef0f33c50220419fb55e9005dacfe273c5ea8c833f9e"
  },
  "kernelspec": {
   "display_name": "Python 3.7.11 64-bit ('cuda': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
